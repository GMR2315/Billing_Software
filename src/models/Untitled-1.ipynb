{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from flask import Flask, render_template, Response, jsonify\n",
    "\n",
    "app = Flask(_name_)\n",
    "\n",
    "# Initialize MediaPipe FaceMesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "blink_detected = False\n",
    "face_detected = False\n",
    "blink_ready = False\n",
    "previous_landmarks = None\n",
    "movement_threshold = 0.01  # Define movement threshold to detect real face\n",
    "\n",
    "# Function to calculate Eye Aspect Ratio (EAR)\n",
    "def calculate_ear(eye):\n",
    "    A = np.linalg.norm(np.array([eye[1].x, eye[1].y]) - np.array([eye[5].x, eye[5].y]))\n",
    "    B = np.linalg.norm(np.array([eye[2].x, eye[2].y]) - np.array([eye[4].x, eye[4].y]))\n",
    "    C = np.linalg.norm(np.array([eye[0].x, eye[0].y]) - np.array([eye[3].x, eye[3].y]))\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "# Function to detect blink and ensure the face is real (not a photo)\n",
    "def detect_blink_and_real_face(landmarks):\n",
    "    global blink_detected, face_detected, blink_ready, previous_landmarks\n",
    "\n",
    "    # Indices for left and right eye landmarks (from MediaPipe FaceMesh)\n",
    "    left_eye_indices = [33, 160, 158, 133, 153, 144]\n",
    "    right_eye_indices = [362, 385, 387, 263, 373, 380]\n",
    "\n",
    "    # Extract landmarks for left and right eyes\n",
    "    left_eye_landmarks = [landmarks[i] for i in left_eye_indices]\n",
    "    right_eye_landmarks = [landmarks[i] for i in right_eye_indices]\n",
    "\n",
    "    # Calculate EAR for both eyes\n",
    "    left_eye_ear = calculate_ear(left_eye_landmarks)\n",
    "    right_eye_ear = calculate_ear(right_eye_landmarks)\n",
    "\n",
    "    # Blink detection threshold\n",
    "    blink_threshold = 0.25\n",
    "\n",
    "    # If the EAR falls below threshold, we detect a blink (eyes closed)\n",
    "    if left_eye_ear < blink_threshold and right_eye_ear < blink_threshold:\n",
    "        blink_ready = True  # Blink is ready when eyes are closed\n",
    "    elif blink_ready and left_eye_ear > blink_threshold and right_eye_ear > blink_threshold:\n",
    "        # Once the eyes are open again after a blink, check for real movement\n",
    "        if detect_real_face_movement(landmarks):\n",
    "            blink_ready = False\n",
    "            blink_detected = True\n",
    "            face_detected = True\n",
    "    return face_detected\n",
    "\n",
    "# Function to detect real movement by comparing previous and current landmarks\n",
    "def detect_real_face_movement(landmarks):\n",
    "    global previous_landmarks, movement_threshold\n",
    "\n",
    "    if previous_landmarks is None:\n",
    "        previous_landmarks = landmarks\n",
    "        return False  # No movement detected for the first frame\n",
    "\n",
    "    total_movement = 0\n",
    "    num_landmarks = len(landmarks)\n",
    "\n",
    "    # Compare current landmarks with previous landmarks\n",
    "    for i in range(num_landmarks):\n",
    "        movement = np.linalg.norm(np.array([landmarks[i].x, landmarks[i].y]) - np.array([previous_landmarks[i].x, previous_landmarks[i].y]))\n",
    "        total_movement += movement\n",
    "\n",
    "    # Calculate the average movement across landmarks\n",
    "    average_movement = total_movement / num_landmarks\n",
    "\n",
    "    # Update the previous landmarks\n",
    "    previous_landmarks = landmarks\n",
    "\n",
    "    # If the average movement is greater than the threshold, it's a real face\n",
    "    if average_movement > movement_threshold:\n",
    "        return True  # Real movement detected\n",
    "    return False  # No real movement detected\n",
    "\n",
    "# Generate frames from the webcam\n",
    "def generate_frames():\n",
    "    global blink_detected, face_detected\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        if not face_detected:\n",
    "            # Convert frame to RGB for MediaPipe\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            result = face_mesh.process(rgb_frame)\n",
    "\n",
    "            if result.multi_face_landmarks:\n",
    "                for face_landmarks in result.multi_face_landmarks:\n",
    "                    # Detect blink and ensure it's a real face\n",
    "                    detect_blink_and_real_face(face_landmarks.landmark)\n",
    "\n",
    "                    if face_detected:\n",
    "                        cv2.putText(frame, 'Face Detected After Blink', (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                        break\n",
    "                    else:\n",
    "                        cv2.putText(frame, 'Blink to Detect Real Face', (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                cv2.putText(frame, 'No Face Detected', (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "            cv2.putText(frame, 'Face Detected After Blink', (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Encode the frame to JPEG\n",
    "        ret, buffer = cv2.imencode('.jpg', frame)\n",
    "        frame = buffer.tobytes()\n",
    "\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# Flask routes\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "@app.route('/retry')\n",
    "def retry():\n",
    "    global blink_detected, face_detected\n",
    "    blink_detected = False\n",
    "    face_detected = False\n",
    "    return jsonify(success=True)\n",
    "\n",
    "if _name_ == '_main_':\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
